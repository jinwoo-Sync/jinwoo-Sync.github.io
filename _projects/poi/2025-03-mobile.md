---
layout: project
title: Real-time POI Detection System for Mobile Devices
category: Real-time POI Detection
date: 2025-03-01
period: 2024.10 - Present
role: Lead Developer
tech: C++, CUDA, TensorRT, Mobile Optimization, Real-time Processing
thumbnail: /assets/images/poi/mobile-thumb.png
---

## 프로젝트 개요

모바일 MMS(Mobile Mapping System) 환경에서 실시간으로 POI(Point of Interest)를 검출하는 시스템을 개발하고 있습니다. 제한된 컴퓨팅 리소스 환경에서 고속 처리와 높은 정확도를 동시에 달성하는 것이 핵심 목표입니다.

## 기술적 도전

### 모바일 환경의 제약사항

- **제한된 전력**: 배터리 구동 시스템
- **제한된 메모리**: 8GB RAM 제약
- **제한된 연산 능력**: 임베디드 GPU (Jetson Xavier)
- **실시간 요구사항**: 10fps 이상 처리 필요
- **높은 정확도 요구**: Detection Precision > 90%

## 시스템 아키텍처

### 전체 파이프라인

```cpp
class MobilePOIDetectionSystem {
private:
    // 입력 스트림
    CameraStream cameraStream;
    LiDARStream lidarStream;
    GPSReceiver gps;

    // 처리 모듈
    std::unique_ptr<LightweightDetector> detector;
    std::unique_ptr<TrackingModule> tracker;
    std::unique_ptr<ClassificationModule> classifier;

    // 결과 관리
    POIDatabase detectedPOIs;
    GeospatialIndex spatialIndex;

public:
    void Run() {
        while (IsRunning()) {
            // 1. 센서 데이터 획득
            auto frame = cameraStream.GetNextFrame();
            auto scan = lidarStream.GetNextScan();
            auto location = gps.GetLocation();

            // 2. 객체 검출
            auto detections = detector->Detect(frame);

            // 3. 3D 위치 추정
            auto positions3D = EstimatePositions(detections, scan);

            // 4. 추적 및 필터링
            auto trackedPOIs = tracker->Update(positions3D);

            // 5. 분류 및 검증
            auto classifiedPOIs = classifier->Classify(trackedPOIs);

            // 6. 저장
            SavePOIs(classifiedPOIs, location);

            // 7. 성능 모니터링
            MonitorPerformance();
        }
    }
};
```

## 핵심 기술

### 1. 경량화 검출 모델

MobileNetV3 + SSDLite 기반 경량 검출 모델을 최적화했습니다.

```cpp
class LightweightDetector {
private:
    // TensorRT 엔진
    std::unique_ptr<nvinfer1::ICudaEngine> engine;
    std::unique_ptr<nvinfer1::IExecutionContext> context;

    // 입출력 버퍼
    CudaBuffer inputBuffer;
    CudaBuffer outputBuffer;

    // 전처리 파이프라인
    PreprocessingPipeline preprocessor;

public:
    std::vector<Detection> Detect(const cv::Mat& image) {
        // 1. 전처리 (GPU에서 직접 수행)
        preprocessor.Process(image, inputBuffer);

        // 2. 추론
        context->executeV2(GetBindings());

        // 3. 후처리
        return PostProcess(outputBuffer);
    }

private:
    std::vector<Detection> PostProcess(const CudaBuffer& output) {
        std::vector<Detection> results;

        // NMS (Non-Maximum Suppression) on GPU
        auto filtered = CudaNMS(output, nmsThreshold);

        // 신뢰도 필터링
        for (const auto& det : filtered) {
            if (det.confidence > confidenceThreshold) {
                results.push_back(det);
            }
        }

        return results;
    }
};
```

**모델 최적화 기법:**

1. **Quantization**: INT8 양자화로 4배 속도 향상
2. **Pruning**: 중요도 낮은 가중치 제거 (30% 파라미터 감소)
3. **Knowledge Distillation**: 대형 모델의 지식 전이
4. **Layer Fusion**: 연산 그래프 최적화

```python
# 모델 최적화 스크립트
def optimize_model(model_path):
    # 1. TensorRT 변환
    trt_model = tensorrt_converter.convert(
        model_path,
        precision_mode='INT8',
        calibration_data=calibration_dataset
    )

    # 2. 레이어 융합
    trt_model.fuse_layers([
        ['conv', 'bn', 'relu'],
        ['conv', 'bn']
    ])

    # 3. 최적화 프로파일 설정
    trt_model.set_optimization_profile(
        min_batch=1,
        opt_batch=1,
        max_batch=1,
        input_shape=(3, 416, 416)
    )

    return trt_model
```

### 2. 효율적인 3D 위치 추정

카메라와 LiDAR 융합을 통한 정확한 3D 위치 추정:

```cpp
class Position3DEstimator {
public:
    struct Position3D {
        Eigen::Vector3d position;
        double confidence;
        double uncertainty;
    };

    Position3D Estimate(
        const Detection& detection,
        const PointCloud& scan,
        const CameraCalibration& calib
    ) {
        // 1. 2D bbox를 3D로 역투영
        auto frustum = BackprojectToFrustum(detection.bbox, calib);

        // 2. Frustum 내 포인트 추출
        auto pointsInFrustum = ExtractPointsInFrustum(scan, frustum);

        if (pointsInFrustum.empty()) {
            return EstimateFromMonocular(detection, calib);
        }

        // 3. 클러스터링
        auto cluster = ClusterPoints(pointsInFrustum);

        // 4. 중심점 계산
        auto center = ComputeCentroid(cluster);

        // 5. 불확실성 추정
        auto uncertainty = EstimateUncertainty(cluster);

        return Position3D {
            .position = center,
            .confidence = ComputeConfidence(cluster, detection),
            .uncertainty = uncertainty
        };
    }

private:
    Eigen::Vector3d EstimateFromMonocular(
        const Detection& det,
        const CameraCalibration& calib
    ) {
        // 단안 카메라 거리 추정 (딥러닝 기반)
        auto depth = depthEstimator->Estimate(det);

        // 역투영
        return Backproject(det.center, depth, calib);
    }
};
```

### 3. 다중 객체 추적

칼만 필터 기반 실시간 추적 시스템:

```cpp
class MultiObjectTracker {
private:
    struct Track {
        int id;
        KalmanFilter filter;
        std::deque<Detection> history;
        int missingFrames;
        POIType type;
    };

    std::vector<Track> activeTracks;
    int nextTrackID = 0;

public:
    std::vector<TrackedPOI> Update(
        const std::vector<Detection>& detections
    ) {
        // 1. Prediction
        for (auto& track : activeTracks) {
            track.filter.Predict();
        }

        // 2. Data Association (Hungarian Algorithm)
        auto assignments = AssociateDetections(detections);

        // 3. Update matched tracks
        for (const auto& [trackIdx, detIdx] : assignments) {
            activeTracks[trackIdx].filter.Update(detections[detIdx]);
            activeTracks[trackIdx].history.push_back(detections[detIdx]);
            activeTracks[trackIdx].missingFrames = 0;
        }

        // 4. Create new tracks
        for (size_t i = 0; i < detections.size(); ++i) {
            if (!IsAssigned(i, assignments)) {
                CreateNewTrack(detections[i]);
            }
        }

        // 5. Remove lost tracks
        RemoveLostTracks();

        // 6. Extract stable POIs
        return ExtractStablePOIs();
    }

private:
    std::vector<TrackedPOI> ExtractStablePOIs() {
        std::vector<TrackedPOI> results;

        for (const auto& track : activeTracks) {
            // 최소 3프레임 이상 추적된 객체만
            if (track.history.size() >= 3) {
                // 위치 안정성 확인
                if (IsPositionStable(track)) {
                    results.push_back(ConvertToTrackedPOI(track));
                }
            }
        }

        return results;
    }

    bool IsPositionStable(const Track& track) {
        if (track.history.size() < 3) return false;

        // 최근 3개 관측값의 표준편차 계산
        std::vector<Eigen::Vector3d> positions;
        for (size_t i = track.history.size() - 3;
             i < track.history.size(); ++i) {
            positions.push_back(track.history[i].position);
        }

        auto stddev = ComputeStdDev(positions);

        // 임계값 이하면 안정적
        return stddev < stabilityThreshold;
    }
};
```

### 4. 실시간 성능 최적화

#### GPU 파이프라인 최적화

```cpp
class GPUOptimizedPipeline {
private:
    // CUDA 스트림 (비동기 처리)
    cudaStream_t preprocessStream;
    cudaStream_t inferenceStream;
    cudaStream_t postprocessStream;

    // 더블 버퍼링
    CudaBuffer bufferA, bufferB;
    bool useBufferA = true;

public:
    void ProcessAsync(const cv::Mat& frame) {
        // 현재 버퍼 선택
        auto& currentBuffer = useBufferA ? bufferA : bufferB;
        auto& nextBuffer = useBufferA ? bufferB : bufferA;

        // 비동기 전처리 (다음 프레임)
        PreprocessAsync(frame, nextBuffer, preprocessStream);

        // 추론 (현재 프레임)
        InferAsync(currentBuffer, inferenceStream);

        // 후처리 완료 대기
        WaitForCompletion(postprocessStream);

        // 버퍼 스왑
        useBufferA = !useBufferA;
    }

private:
    void PreprocessAsync(
        const cv::Mat& image,
        CudaBuffer& buffer,
        cudaStream_t stream
    ) {
        // GPU 메모리로 복사
        cudaMemcpyAsync(
            buffer.device,
            image.data,
            buffer.size,
            cudaMemcpyHostToDevice,
            stream
        );

        // 전처리 커널 실행
        LaunchPreprocessKernel(buffer, stream);
    }
};
```

#### 메모리 최적화

```cpp
class MemoryOptimizer {
private:
    // 메모리 풀
    CudaMemoryPool gpuPool;
    std::unique_ptr<ObjectPool<PointCloud>> cloudPool;
    std::unique_ptr<ObjectPool<cv::Mat>> imagePool;

public:
    // 메모리 재사용
    template<typename T>
    std::unique_ptr<T> Acquire() {
        return GetPool<T>().Acquire();
    }

    template<typename T>
    void Release(std::unique_ptr<T> obj) {
        GetPool<T>().Release(std::move(obj));
    }

    // 메모리 사용량 모니터링
    void MonitorUsage() {
        size_t free, total;
        cudaMemGetInfo(&free, &total);

        double usage = (total - free) / static_cast<double>(total);

        if (usage > 0.9) {
            TriggerGarbageCollection();
        }
    }
};
```

## POI 분류 및 검증

### 딥러닝 기반 분류기

```cpp
class POIClassifier {
private:
    // 분류 모델
    std::unique_ptr<TRTClassifier> classifier;

    // POI 타입 정의
    enum class POIType {
        TrafficSign,
        TrafficLight,
        Pole,
        Building,
        Tree,
        Unknown
    };

public:
    ClassificationResult Classify(const TrackedPOI& poi) {
        // 1. ROI 추출
        auto roi = ExtractROI(poi);

        // 2. 특징 추출
        auto features = ExtractFeatures(roi);

        // 3. 분류
        auto probabilities = classifier->Predict(features);

        // 4. 후처리
        return PostProcess(probabilities);
    }

private:
    ClassificationResult PostProcess(
        const std::vector<float>& probs
    ) {
        // Top-k 확률
        auto topK = GetTopK(probs, 3);

        // 신뢰도 검증
        if (topK[0].probability < minConfidence) {
            return ClassificationResult::Unknown();
        }

        // 시간적 일관성 확인
        if (!IsConsistentWithHistory(topK[0].type)) {
            return ClassificationResult::Uncertain();
        }

        return ClassificationResult {
            .type = topK[0].type,
            .confidence = topK[0].probability,
            .alternatives = topK
        };
    }
};
```

### 규칙 기반 검증

```cpp
class POIValidator {
public:
    bool Validate(const ClassifiedPOI& poi) {
        // 1. 위치 타당성
        if (!IsLocationValid(poi)) return false;

        // 2. 크기 타당성
        if (!IsSizeReasonable(poi)) return false;

        // 3. 맥락 일관성
        if (!IsContextConsistent(poi)) return false;

        // 4. 시간적 안정성
        if (!IsTemporallyStable(poi)) return false;

        return true;
    }

private:
    bool IsLocationValid(const ClassifiedPOI& poi) {
        // 교통 표지는 도로 근처에만
        if (poi.type == POIType::TrafficSign) {
            return IsNearRoad(poi.position);
        }

        // 신호등은 교차로 근처에만
        if (poi.type == POIType::TrafficLight) {
            return IsNearIntersection(poi.position);
        }

        return true;
    }

    bool IsSizeReasonable(const ClassifiedPOI& poi) {
        auto sizeRange = GetExpectedSizeRange(poi.type);
        return poi.size >= sizeRange.min &&
               poi.size <= sizeRange.max;
    }
};
```

## 성능 최적화 결과

### 처리 속도

| 메트릭 | 최적화 전 | 최적화 후 | 개선율 |
|--------|-----------|-----------|--------|
| Detection | 120ms | 35ms | 71% |
| Tracking | 25ms | 8ms | 68% |
| Classification | 80ms | 20ms | 75% |
| **Total** | **225ms (4.4fps)** | **63ms (15.9fps)** | **72%** |

### 정확도

- **Detection Precision**: 92.5%
- **Detection Recall**: 89.3%
- **Classification Accuracy**: 94.2%
- **False Positive Rate**: < 5%

### 리소스 사용

- **GPU 메모리**: 2.8GB (8GB 중)
- **CPU 사용률**: ~45%
- **전력 소비**: 15W (평균)
- **배터리 운용 시간**: 6시간+

## 실제 적용 사례

### 도심 주행 테스트

- **테스트 거리**: 50km
- **검출된 POI**: 3,247개
- **처리 시간**: 3시간 12분
- **평균 FPS**: 14.8fps
- **실패율**: < 3%

### 고속도로 주행 테스트

- **테스트 거리**: 100km
- **검출된 POI**: 1,856개
- **처리 시간**: 2시간 45분
- **평균 FPS**: 15.2fps
- **실패율**: < 2%

## 기술적 도전과 해결

### 도전 1: 실시간 성능과 정확도 트레이드오프

**해결책**:
- 적응형 해상도 조절 (거리에 따라)
- ROI 기반 선택적 고해상도 처리
- 시간적 정보 활용 (추적)

### 도전 2: 제한된 메모리

**해결책**:
- 스트리밍 처리 (배치 처리 X)
- 메모리 풀링
- 지능형 캐싱 전략

### 도전 3: 다양한 환경 조건

**해결책**:
- 데이터 증강으로 강건성 확보
- 적응형 임계값 조정
- 앙상블 기법 적용

## 향후 계획

- **모델 경량화**: MobileNetV4, EfficientNet 적용
- **엣지 컴퓨팅**: 로컬 처리 + 클라우드 검증 하이브리드
- **Active Learning**: 실제 주행 데이터로 지속 학습
- **멀티모달 융합**: 카메라 + LiDAR + Radar 통합

## 사용 기술

- C++17, CUDA 11.4
- TensorRT 8.x
- OpenCV 4.x (CUDA 지원)
- Eigen 3.x
- NVIDIA Jetson Xavier

현재 프로젝트는 활발히 진행 중이며, 실제 상용 시스템 배포를 목표로 하고 있습니다.
